{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Desafio GPAM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NelusZnnIlLS",
        "colab_type": "text"
      },
      "source": [
        "# Sobre\n",
        "\n",
        "Este notebook contém os tópicos para a avaliação da segunda fase do processo seletivo do GPAM, 2/2019. A avaliação consiste na criação de um modelo para a classificação de discurso de ódio utilizando texto, usufruindo do dataset disponibilizado [no kaggle](https://www.kaggle.com/arkhoshghalb/twitter-sentiment-analysis-hatred-speech#train.csv).\n",
        "\n",
        "Autor: Roger Lenke  \n",
        "Matrícula: 15/0021437  \n",
        "Email: rogerlenke@gmail.com  \n",
        "\n",
        "Fontes utilizadas:  \n",
        "[Machine Learning - Text Processing](https://towardsdatascience.com/machine-learning-text-processing-1d5a2d638958)  \n",
        "[Working with Text Data - Sklearn](https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)  \n",
        "[Natural Language Processing(NLP) for Machine Learning](https://towardsdatascience.com/natural-language-processing-nlp-for-machine-learning-d44498845d5b)  \n",
        "[Feature Engineering for Twitter-based Applications](https://www.researchgate.net/publication/320550509_Feature_Engineering_for_Twitter-based_Applications)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnivgzziIzR3",
        "colab_type": "text"
      },
      "source": [
        "# Análise Exploratória dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnBwGWUfQFrO",
        "colab_type": "code",
        "outputId": "1633dfd4-5280-40bb-9356-c3345ad939ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "  import nltk\n",
        "except:\n",
        "  !pip install nltk\n",
        "  import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV3iYlb2Fe-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading the train dataset, which will be the only one used in this competition.\n",
        "\n",
        "train_df = pd.read_csv('train.csv', encoding='utf8')\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MB6V_UQYFYZg",
        "colab_type": "text"
      },
      "source": [
        "## Análise Geral"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWTRANksSBlY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giCwtJxPRz6U",
        "colab_type": "text"
      },
      "source": [
        "O dataset consiste em 31962 tweets, cada um classificado com a label  para tweets usuais e 1 para tweets com discurso de ódio. De acordo com a página do dataset, um tweet é classificado como discurso de ódio caso contenha racismo e/ou sexismo. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq4Jc52LSjkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check for missing data.\n",
        "train_df['tweet'].isna().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw2oGybvQi2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_normal_tweets = train_df[train_df['label'] == 0].shape[0]\n",
        "num_hate_tweets = train_df[train_df['label'] == 1].shape[0]\n",
        "\n",
        "plt.pie([num_normal_tweets, num_hate_tweets], explode=[0.0, 0.2],\n",
        "        labels=['Normal tweets', 'Hate speech tweets'],\n",
        "        autopct='%1.1f%%');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2KbJVNES09w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'Num normal tweets: {num_normal_tweets}')\n",
        "print(f'Num hate tweets: {num_hate_tweets}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v40paf6iUk1p",
        "colab_type": "text"
      },
      "source": [
        "O dataset está extremamente desbalanceado, com mais de 93% dos exemplos sendo de tweets usuais, e apenas 7% de tweets com discurso de ódio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5SXUkyjFljL",
        "colab_type": "text"
      },
      "source": [
        "## Frequência de Palavras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxGJWUBO9hy2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Concatenate all tweets in a string separating each tweet with a space.\n",
        "tweets = train_df['tweet'].str.cat(sep=' ')\n",
        "\n",
        "# Tokenize each word\n",
        "tokens = word_tokenize(tweets)\n",
        "\n",
        "def plot_words(tokens, amount, top=True):\n",
        "  frequency = nltk.FreqDist(tokens)\n",
        "  top_words = sorted(frequency, key=frequency.__getitem__, reverse=top)[:amount]\n",
        "  top_words_counts = sorted(list(frequency.values()), reverse=top)[:amount]\n",
        "  plt.plot(top_words, top_words_counts)\n",
        "  plt.xticks(top_words, rotation='vertical');\n",
        "\n",
        "plt.show()\n",
        "plt.subplot(311)\n",
        "plot_words(tokens, 25)\n",
        "plt.subplot(313)\n",
        "plot_words(tokens, 25, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf5F7SLdmsRT",
        "colab_type": "text"
      },
      "source": [
        "Existem alguns caracteres de marcação comuns ao twitter (#, @, user) dentre os 25 tokens mais utilizados no corpo de texto, além de sinais de pontuação e stop-words. Algumas das palavras menos utilizadas contém caracteres ilógicos e números."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYkk9ZtSHx8B",
        "colab_type": "text"
      },
      "source": [
        "## Hashtags e Menções"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOf23OIUGqm6",
        "colab_type": "text"
      },
      "source": [
        "Segundo o artigo *Feature Engineering for Twitter-based Applications*, as aplicações que utilizam dados do Twitter para realizar previsões podem se aproveitar de aspectos do texto e meta-dados, como as *hashtags* e as menções a outros usuários. Infelizmente, o dataset de treino não fornece metadados sobre os tweets presentes. Apesar disto, é possível retirar informações de *hashtags* e menções do texto disponível."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usOcIneqFZgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "expression = '#\\w+'\n",
        "train_df['hashtags'] = train_df['tweet'].apply(lambda tweet: re.findall(expression, tweet))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rs7Sdm5jTe_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bins = np.linspace(0, 20, 20)\n",
        "\n",
        "train_df['num_hashtags'] = train_df['hashtags'].apply(lambda hashtags: len(hashtags))\n",
        "\n",
        "plt.hist(train_df[train_df['label'] == 0]['num_hashtags'], bins, alpha=0.5, label='normal');\n",
        "plt.hist(train_df[train_df['label'] == 1]['num_hashtags'], bins, alpha=0.5, label='hate');\n",
        "plt.legend(loc='upper left')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQmpRl6s2TgJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flatten(l):\n",
        "  return [item for sublist in l for item in sublist]\n",
        "\n",
        "hashtags_normal = flatten(train_df[train_df['label'] == 0]['hashtags'].values)\n",
        "hashtags_hate = flatten(train_df[train_df['label'] == 1]['hashtags'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEXsMNms6ipj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "def most_common_hashtags(hashtags, amount):\n",
        "  pair = [(hashtag, hashtag_count) for hashtag, hashtag_count in Counter(hashtags).most_common(amount)]\n",
        "  hashtags = [hashtag for (hashtag, _) in pair]\n",
        "  count = [count for (_, count) in pair]\n",
        "  return hashtags, count\n",
        "\n",
        "common_normal_hashtags, count_normal_hashtags = most_common_hashtags(hashtags_normal, 20)\n",
        "common_hate_hashtags, count_hate_hashtags = most_common_hashtags(hashtags_hate, 20)\n",
        "\n",
        "def plot_hashtags(labels, count):\n",
        "  index = np.arange(0, len(labels))\n",
        "  plt.bar(index, count)\n",
        "  plt.xticks(index, labels, rotation='vertical');\n",
        "\n",
        "plt.subplot(311)\n",
        "plot_hashtags(common_normal_hashtags, count_normal_hashtags)\n",
        "plt.subplot(313)\n",
        "plot_hashtags(common_hate_hashtags, count_hate_hashtags)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPfqADx2jUpo",
        "colab_type": "text"
      },
      "source": [
        "O histograma demonstra que não há diferença na quantidade média de hashtags utilizadas nos tweets com discurso de ódio e tweets usuais. Porém, as hashtags mais utilizadas nos tweets de ódio são diferentes das hashtags mais utilizadas nos tweets usuais. Isto pode indicar que a feature hashtags é um bom diferenciador entre tweets com e sem discurso de ódio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OHqn1WRH4Ir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "expression = '@user'\n",
        "train_df['mentions'] = train_df['tweet'].apply(lambda tweet: len(re.findall(expression, tweet)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNLr5seOIZEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bins = np.linspace(0, 20, 20)\n",
        "\n",
        "plt.hist(train_df[train_df['label'] == 0]['mentions'], bins, alpha=0.5, label='normal');\n",
        "plt.hist(train_df[train_df['label'] == 1]['mentions'], bins, alpha=0.5, label='hate');\n",
        "plt.legend(loc='upper left');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rvwt8r9Iq6i",
        "colab_type": "text"
      },
      "source": [
        "O histograma denota que o número de mentions não é relevante para a separação entre os tweets com e sem discurso de ódio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qig_GUj2t1S2",
        "colab_type": "text"
      },
      "source": [
        "# Pré-processamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZkbyfPWJ42P",
        "colab_type": "text"
      },
      "source": [
        "A atividade de pré-processamento inclui a tokenização dos termos do texto, a limpeza de *stopwords*, de caracteres aleatórios, e a redução dos termos a raiz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wd7hmqrF56X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "\n",
        "def clean(tweet):\n",
        "  tweet = word_tokenize(tweet)\n",
        "\n",
        "  # Remove stop words\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  tweet = [x for x in tweet if not x in stop_words]\n",
        "\n",
        "  # Remove Words with numbers\n",
        "  tweet = [x for x in tweet if x.isalpha()]\n",
        "\n",
        "  # Remove non-words\n",
        "  tweet = [x for x in tweet if len(x) > 2]\n",
        "\n",
        "  # Lemmanitize\n",
        "  lemmatizer = WordNetLemmatizer() \n",
        "  tweet = [lemmatizer.lemmatize(x) for x in tweet]\n",
        "\n",
        "  # Remove punctuation\n",
        "  tweet = [x for x in tweet if x not in string.punctuation]\n",
        "\n",
        "  return tweet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wSIX3Xot3r7",
        "colab_type": "text"
      },
      "source": [
        "# Escolha das Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAuIcnqFM97p",
        "colab_type": "text"
      },
      "source": [
        "O processo de extração das features envolve a conversão dos tokens de cada tweet para um formato que possa ser utilizados por modelos de aprendizado de máquina. Aqui, é utilizado o processo de word embedding, no qual palavras são representadas num espaço multidimensional, de maneira que palavras de sentido similar ficam mais próximas que palavras não relacionadas.\n",
        "\n",
        "Além disto, o processo também envolve a adição de features extras na matriz gerada. Aqui, as hashtags utilizadas em cada tweet são adicionadas a matriz, a fim de atingir uma melhor capacidade de previsão.\n",
        "\n",
        "Pelo fato dos dados de treinamento estarem bastante desbalanceados, optou-se por realizar um *undersampling* dos dados, especificamente os dados de tweets normais. Assim, espera-se evitar a situação de overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTNP6DK-K0sL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize(dataframe):\n",
        "  tf_vectorizer = TfidfVectorizer(analyzer=clean)\n",
        "  X_train_idf = tf_vectorizer.fit_transform(dataframe)\n",
        "  return X_train_idf\n",
        "\n",
        "X_train_idf = vectorize(train_df['tweet'])\n",
        "X_train_idf.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR8fHyrYMKCi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import scipy as sp\n",
        "\n",
        "def add_columns(matrix, dataframe):\n",
        "  mlb = MultiLabelBinarizer(sparse_output=True)\n",
        "  matrix = sp.sparse.hstack((matrix, mlb.fit_transform(dataframe)))\n",
        "  return matrix\n",
        "\n",
        "X_train_idf = add_columns(X_train_idf, train_df['hashtags'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbecOaQht6Dm",
        "colab_type": "text"
      },
      "source": [
        "# Criação do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJlZ_FCEPLn9",
        "colab_type": "text"
      },
      "source": [
        "Para o desafio, optou-se por utilizar o modelo SVM, ou *Support Vector Machines*.\n",
        "\n",
        "O modelo SVM procura encontrar um hiperplano num espaço multidimensional onde estejam distribuídos os dados, de maneira que este hiperplano seja o que melhor separe as diferentes classes destes dados.\n",
        "\n",
        "Existem diversos hiperplanos que separam os dados num espaço n-dimensional. O hiperplano escolhido pelo algoritmo SVM é aquele que maximiza a distância dentre os pontos de dados de cada classe que estão mais próximos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jusgG8sRDOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "svm = SVC(probability=True, kernel='linear')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mxbM8mKt87L",
        "colab_type": "text"
      },
      "source": [
        "# Treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoKDJ_i_Q3dO",
        "colab_type": "text"
      },
      "source": [
        "Nesta etapa, foi realizada a divisão do dataset de treinamento entre dataset de treino e teste, de maneira a permitir uma avaliação da generalização do modelo criado em dados os quais não foram utilizados para treinamento.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d628pDwERbD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train_idf, train_df['label'], test_size=0.2, random_state=666)\n",
        "\n",
        "svm.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY--LC-ruBtb",
        "colab_type": "text"
      },
      "source": [
        "# Escolha da métrica"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-YZjZ9lh3qv",
        "colab_type": "text"
      },
      "source": [
        "Devido ao desbalanceamento entre a quantidade de amostras da classe de tweets com discurso de ódio e classe de tweets sem discurso de ódio, a métrica de acurácia não é confiável para medir a qualidade do modelo, já que considera apenas a quantidade de previsões corretas em relação ao total de previsões.\n",
        "\n",
        "As métricas de precisão e recall consideram, ambas, o **custo** de se realizar uma predição, de maneira que a precisão é utilizada quando a preocupação é evitar falsos positivos, enquanto o recall é a métrica utilizada quando o objetivo é selecionar o modelo que melhor evita falsos negativos.\n",
        "\n",
        "Considerando que o modelo construído poderia ser utilizado para moderar os tweets realizados por usuários do twitter, é importante considerar tanto o custo de apagar um tweet que não contém discurso de ódio (falso positivo) quando o custo de não apagar um tweet que contém discurso de ódio (falso negativo). Por isto, a métrica **F1-Score**, que considera ambas a precisão e o recall, foi a escolhida para avaliar o modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e95x02gfUNRl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "y_pred = svm.predict(X_train)\n",
        "print(f'F1 Score for training: {f1_score(y_train, y_pred)}')\n",
        "\n",
        "y_pred = svm.predict(X_test)\n",
        "print(f'F1 Score for test: {f1_score(y_test, y_pred)}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FE0PXbPuC9F",
        "colab_type": "text"
      },
      "source": [
        "# Avaliação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiBNAMi6XU98",
        "colab_type": "text"
      },
      "source": [
        "Para a visualização do score de acordo com a métrica F1, é obtida a probabilidade de um valor pertencer ou não a classe de tweets com discursos de ódio, para todos os tweets. Após isto, é plotado um gráfico variando o f1-score de acordo com diferentes *thresholds*, i.e, diferentes porcentagens que determinam se um dado será ou não predito como tweet com discurso de ódio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsaRxgDqQiut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "proba = svm.predict_proba(X_test)\n",
        "proba = proba[:, 1]\n",
        "thresholds = np.arange(0.1, 0.9, 0.1)\n",
        "\n",
        "scores = [f1_score(y_test, proba >= x) for x in thresholds]\n",
        "\n",
        "plt.plot(thresholds, scores);\n",
        "plt.title('F1-score with different thresholds');\n",
        "plt.ylabel(\"F1-Score\");\n",
        "plt.xlabel(\"Threshold\");\n",
        "plt.show();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXW5J5HtX0vQ",
        "colab_type": "text"
      },
      "source": [
        "O gráfico demonstra que o score mais alto é obtido quando o threshold é fixado em 0.2, o que significa que qualquer tweet com 20% ou mais de probabilidade de conter discurso de ódio é classificado como tal."
      ]
    }
  ]
}
